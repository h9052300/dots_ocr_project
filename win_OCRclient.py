import time
import requests
import logging
from pathlib import Path

# é…ç½®å€
SERVER_IP = "192.168.204.34"  # è«‹ç¢ºèªä½ çš„ IP
API_URL = f"http://{SERVER_IP}:8000"
INPUT_DIR = r"C:\Users\x1090102\Downloads\batch_input"
OUTPUT_DIR = r"C:\Users\x1090102\Downloads\batch_output"

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)


def process_pipeline(file_path, output_dir):
    filename = file_path.name
    logger.info(f"ğŸš€ [1/3] ä¸Šå‚³æª”æ¡ˆ: {filename}")

    # 1. æäº¤ä»»å‹™ (Submit)
    try:
        with open(file_path, 'rb') as f:
            resp = requests.post(f"{API_URL}/ocr/submit", files={'file': f}, timeout=600)
            if resp.status_code != 200:
                logger.error(f"âŒ ä¸Šå‚³å¤±æ•—: {resp.text}")
                return
            data = resp.json()
            job_id = data['job_id']
            logger.info(f"âœ… ä¸Šå‚³æˆåŠŸ! Job ID: {job_id}")
    except Exception as e:
        logger.error(f"âŒ é€£ç·šéŒ¯èª¤: {e}")
        return

    # 2. è¼ªè©¢é€²åº¦ (Poll)
    logger.info(f"â³ [2/3] ç­‰å¾…ä¼ºæœå™¨è™•ç†... (æ‚¨å¯ä»¥éš¨æ™‚é—œé–‰æ­¤è¦–çª—ï¼Œä»»å‹™ä¸æœƒä¸­æ–·)")
    last_progress = ""

    while True:
        try:
            status_resp = requests.get(f"{API_URL}/ocr/status/{job_id}", timeout=10)
            if status_resp.status_code != 200:
                print(f"\râŒ æŸ¥è©¢å¤±æ•—...", end="")
                time.sleep(5)
                continue

            info = status_resp.json()
            status = info['status']
            progress = info.get('progress', '')

            # åªåœ¨é€²åº¦æ–‡å­—æ”¹è®Šæ™‚æ‰å°å‡ºï¼Œé¿å…æ´—ç‰ˆ
            if progress != last_progress:
                print(f"\rğŸ”¹ [{status}] é€²åº¦: {progress}" + " " * 20)
                last_progress = progress

            if status == "COMPLETED":
                print("")  # æ›è¡Œ
                logger.info("ğŸ‰ ä¼ºæœå™¨è™•ç†å®Œç•¢!")
                break
            elif status == "FAILED":
                print("")
                logger.error(f"âŒ ä»»å‹™å¤±æ•—: {progress}")
                return

            time.sleep(5)  # æ¯ 5 ç§’æª¢æŸ¥ä¸€æ¬¡

        except KeyboardInterrupt:
            logger.warning("ä½¿ç”¨è€…ä¸­æ–·ç›£æ§ (ä¼ºæœå™¨ä»åœ¨èƒŒæ™¯åŸ·è¡Œ)")
            return
        except Exception as e:
            logger.error(f"è¼ªè©¢éŒ¯èª¤: {e}")
            time.sleep(10)

    # 3. ä¸‹è¼‰çµæœ (Download)
    logger.info(f"â¬‡ï¸ [3/3] ä¸‹è¼‰çµæœ...")
    try:
        download_resp = requests.get(f"{API_URL}/ocr/download/{job_id}", stream=True, timeout=3600)
        if download_resp.status_code == 200:
            output_file = Path(output_dir) / f"{file_path.stem}_searchable.pdf"
            with open(output_file, 'wb') as f:
                for chunk in download_resp.iter_content(chunk_size=8192):
                    f.write(chunk)
            logger.info(f"âœ… æª”æ¡ˆå·²å„²å­˜: {output_file}")
        else:
            logger.error("âŒ ä¸‹è¼‰å¤±æ•—")
    except Exception as e:
        logger.error(f"âŒ ä¸‹è¼‰éç¨‹éŒ¯èª¤: {e}")


def main():
    input_path = Path(INPUT_DIR)
    if not input_path.exists():
        logger.error("æ‰¾ä¸åˆ°è¼¸å…¥è³‡æ–™å¤¾")
        return

    files = list(input_path.glob("*.pdf"))
    logger.info(f"ç™¼ç¾ {len(files)} å€‹ PDFï¼Œé–‹å§‹è™•ç†ä½‡åˆ—...")

    for f in files:
        process_pipeline(f, OUTPUT_DIR)
        print("-" * 50)


if __name__ == "__main__":
    main()